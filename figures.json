[{"figure_path": "https://arxiv.org/html/2410.24175/x1.png", "figure_caption": "Figure 1: Existing datasets inherently include implicit satisfied complex constraints in the responses."}, {"figure_path": "https://arxiv.org/html/2410.24175/x2.png", "figure_caption": "Figure 2: The framework of constructing the proposed alignment training dataset."}, {"figure_path": "https://arxiv.org/html/2410.24175/x3.png", "figure_caption": "Figure 3: An example of responses generated with and without constraints by Llama3-70B-Instruct. The evaluator is gpt-4o-0806. For better visualization, we present only a subset of the responses generated without constraints."}, {"figure_path": "https://arxiv.org/html/2410.24175/x4.png", "figure_caption": "Figure 4: \nFull-mark rates (%) of the responses generated with and without constraints. The evaluator is gpt-4o-0806, focusing on four widely-used dimensions: Engagingness (Eng.), Understandability (Und.), Fluency (Flu.), and Coherence (Coh.)."}, {"figure_path": "https://arxiv.org/html/2410.24175/x5.png", "figure_caption": "Figure 5: \nExperimental results on different categories of constraints in FollowBench of\nMistralCrab and ConiferSFT."}, {"figure_path": "https://arxiv.org/html/2410.24175/x6.png", "figure_caption": "Figure 6:  Proportion (%) of data in the Crab by the number of constraints and the source dataset."}]